{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R2j7l8RCwx4"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=181S0KcAdGeAajZ1apcbOvoh3wvYuKtzd\">\n",
    "<b>Autores</b>:\n",
    "\n",
    "*   Aldo von Wangenheim (aldo.vw@ufsc.br)\n",
    "*   Rodrigo de Paula e Silva Ribeiro (ribeiro.rodrigo@posgrad.ufsc.br)\n",
    "\n",
    "\n",
    "CERTIFIQUE-SE DE TER INCIADO O AMBIENTE EM MODO <b>GPU</b> ANTES DE REALIZAR OS PROCEDIMENTOS.<br>\n",
    "NA TROCA DO AMBIENTE ELE <b><u>PERDE</u></b> TODOS OS DADOS BAIXADOS.\n",
    "\n",
    "AO RE-EXECUTAR OS PROCEDIMENTOS (ex. diminuir o batch size), <br>REINICIE O AMBIENTE PARA LIBERAR O CACHE DO PYTORCH (reiniciar não perde os dados da sessão).<br>(alt+m ou pelo menu \"Ambiente de Execução\")\n",
    "\n",
    "EXECUTE UTILIZANDO RUN ALL ou CTRL+F9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/awangenh/vision/blob/master/jupyter/14.4.Detecção%20de%20Sinais%20de%20Trânsito%20-%20YOLOv10.ipynb\"><img align=\"left\"  src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/License-CC-BY-ND-4.0-orange.png\" alt=\"Creative Commons 4.0 License\" title=\"Creative Commons 4.0 License\"></a>&nbsp; &nbsp; <a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Jupyter-Notebook-v.1.0-blue.png\" alt=\"Jupyter Version\" title=\"Jupyter Version\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\"  src=\"https://img.shields.io/badge/python-3.10-greeng\" alt=\"Python Version\" title=\"Python Version\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9BV-PR-W1u2",
    "outputId": "4c55d966-db86-4ea6-e41b-f5ddfe4f76fe"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlBPQTykbG2d"
   },
   "source": [
    "# Definir a pasta base atual e Configurações GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDFlUtGFbGDT",
    "outputId": "46ddcac3-39c6-43ec-cf1f-1fcfc5c26e60"
   },
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    _ON_COLAB = True\n",
    "except:\n",
    "    _ON_COLAB = False\n",
    "    %reload_ext autoreload\n",
    "    %autoreload 2\n",
    "    %matplotlib inline\n",
    "    from IPython import get_ipython\n",
    "    \n",
    "print('Running on Google Colab = ', _ON_COLAB)\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Definir o caminho base\n",
    "if _ON_COLAB:\n",
    "    BASE_PATH = \"/content\"\n",
    "    import locale\n",
    "    locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "else:\n",
    "    BASE_PATH = \"/lapix\" # trocar para o base path do seu computador se estiver rodando localmente, deixar /lapix se estiver rodando nos conteiners lapix\n",
    "    VISIBLE_GPUS = [7] # Selecionar a GPU PARA RODAR! VER QUAL ESTA LIVRE\n",
    "\n",
    "    if torch.cuda.device_count() != 8:\n",
    "        print(\"GPU SETADA - PULANDO ETAPA\")\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(VISIBLE_GPUS).replace(\"]\", \"\").replace(\"[\",\"\").replace(\" \", \"\")\n",
    "        os.environ[\"NVIDIA_VISIBLE_DEVICES\"] = str(VISIBLE_GPUS).replace(\"]\", \"\").replace(\"[\",\"\").replace(\" \", \"\")\n",
    "        print(\"CUDA GPUS NUMBER: \", torch.cuda.device_count())\n",
    "    \n",
    "os.chdir(BASE_PATH) # garantir que está executando no caminho base definido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TllDbGRUnk6"
   },
   "source": [
    "# O que é YOLO?\n",
    "YOLO (“You Only Look Once”), é uma série de detectores de objetos de processamento rápido que vem sendo desenvolvida por diversos autores. Ao contrário dos detectores tradicionais que utilizam áreas de interesse para propor regiões (ROI) que podem conter um objeto na imagem (conhecidos como detectores de 2-estágios), a arquitetura YOLO divide a imagem em grids e vasculha a imagem como um todo (detector de um único estágio).\n",
    "\n",
    "Neste notebook didático, é utilizado a versão 10 desta arquitetura.<br>\n",
    "Algumas notas sobre a versão 10:<br>\n",
    "* Em uma abordagem nova, foi removido a NMS e trocado por um head 1x1 para reduzir o peso computacional e melhorar a latência.\n",
    "* Assim como a versão 9, a versão 10 é pré-treinada no [COCO Dataset](https://cocodataset.org/#home) e não no ImageNet.\n",
    "* Diferente de outras versões anteriores (9, 7, 6, 4), a versão 10 é construida sobre o Yolo V8, no framework Ultralytics de modo que pode ser executada como módulo cli ou pela lib ultralytics, este notebook utiliza chamada de módulo cli.\n",
    "* Foram realizadas diversas melhorias na arquitetura em relação a inferência, o mais notável é o consumo de VRAM, em comparação com Yolov9 e utilizando o mesmo modelo base, YoloV10 consome quase metade da VRAM, podendo rodar com BATCH maior que o YoloV9 nas mesmas configurações.\n",
    "\n",
    "Diferentemente do Detectron2 (framework customizável), YOLO é uma arquitetura parametrizada e única, embora é possível alterar diversos parâmetros na rotina de treino oficial, muitas alterações ou valores muito diferentes podem descaracterizar a rede perdendo a sua capacidade de atingir resultados SOTA (state of the art).\n",
    "\n",
    "Neste notebook apenas alguns parâmetros de performance são editáveis, para editar parâmetros mais específicos ou até mesmo implementar modificações, é recomendável ler e se familiarizar com a arquitetura.\n",
    "\n",
    "Links:<br>\n",
    "[Link Artigo](https://arxiv.org/abs/2405.14458) <br>\n",
    "[Link git](https://github.com/THU-MIG/yolov10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrLaA--UTwnj"
   },
   "source": [
    "# Instalação do YoloV10 do repositório oficial e suas dependências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfRGCg8rbWmp",
    "outputId": "af0bb156-be00-42b2-c653-4d789df0ca18"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/THU-MIG/yolov10.git\n",
    "os.chdir(os.path.join(HOME_DIR, \"yolov10\"))\n",
    "!pip install -r requirements.txt\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOZzHrymT_Wv"
   },
   "source": [
    "# Montar o google drive\n",
    "As 'runs' de treino serão salvas na pasta \"aula_yolov10\" no seu drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNjMVBzfT30G"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(os.path.join(BASE_PATH, 'gdrive'), force_remount=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM6ZuDTLV-Xh"
   },
   "source": [
    "# Baixar o dataset de itens de trânsito já no formato YOLO\n",
    "O dataset de itens de trânsito tem como objetivo didático demonstrar a possibilidade de identificar alguns itens comuns de trânsito.<br>\n",
    "É um conjunto anotado no formato \"bounding box\" para detecção de objetos.<br>\n",
    "O conjunto possui 4 classes distintas:\n",
    "* trafficlight\n",
    "* stop\n",
    "* speedlimit\n",
    "* crosswalk\n",
    "\n",
    "Amostra de anotações:<br>\n",
    "<img src=\"https://drive.google.com/uc?id=1AoC87UUaJ5v3W03mTE6gQocW6sYgCEuz\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bu6VgY8uV2u4",
    "outputId": "127ff6c1-f061-45ff-a73b-74c6efea56e1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(BASE_PATH)\n",
    "!gdown 1sIhCtoOMnpCXlByxDV95iRQDWjTPKr9v\n",
    "!unzip -qq -u trafficsign.zip\n",
    "!rm -rf trafficsign.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LecEvYduXdc"
   },
   "source": [
    "# Baixar o peso do modelo padrão para transfer learning.\n",
    "Para mais opções de pesos pré-treinados e modelos maiores/menores, ver o github oficial do [YoloV10](https://github.com/THU-MIG/yolov10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52uZgsQLuSO2",
    "outputId": "0828f0f5-e1c8-4494-de6a-c30ab1a91488"
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(BASE_PATH, \"yolov10\"))\n",
    "!wget https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10m.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfJYfYewjzuc"
   },
   "source": [
    "# Parâmetros básicos\n",
    "Implementação de edição dos parâmetros básicos de performance do Yolo v10.<br>\n",
    "Para parâmetros opcionais e outros, ver [a documentação da ultralytics](https://docs.ultralytics.com/modes/train/#train-settings) e adequar o código.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V4_MW1SXGY_"
   },
   "outputs": [],
   "source": [
    "# Definir onde salvar os resultados de treino\n",
    "#SAVE_PATH = \"/content/gdrive/MyDrive/aula_yoloV10/\" # salvar no drive\n",
    "SAVE_PATH = os.path.join(BASE_PATH, \"yolov10_run\") # salvar no ambiente local\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Definir o batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Definir o número de épocas de treino\n",
    "EPOCHS = 10\n",
    "\n",
    "# Definir o formato de imagem para rede\n",
    "IM_SIZE = 640 # padrão 640, imagem menor = mais rápido, menos preciso em objetos pequenos; imagem maior = mais lento, mais preciso em objetos pequenos.\n",
    "\n",
    "# Definir GPU a ser utilizada\n",
    "GPU_USE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKh0F_Te1dcQ",
    "outputId": "2c996fed-0e34-44a9-cf92-29f71b440a9f"
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(BASE_PATH, \"yolov10\"))\n",
    "!yolo task=detect mode=train data=\"{BASE_PATH}/trafficsign/data.yaml\" model=\"yolov10m.pt\" epochs={EPOCHS} batch={BATCH_SIZE} imgsz={IM_SIZE} project={SAVE_PATH} device={GPU_USE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Pln7M0P_tvC"
   },
   "source": [
    "# Gráficos de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Y9Q-c9sJ_VKu",
    "outputId": "c76f57dd-f624-4188-f183-9a665f48a876"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "metrics_img = glob(os.path.join(SAVE_PATH, 'train/*.png'))\n",
    "n_img = len(metrics_img)\n",
    "n_cols = 2\n",
    "n_rows = int(n_img / n_cols) + (1 if n_img % n_cols != 0 else 0)\n",
    "_, axs = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "for m, ax in zip(metrics_img, axs):\n",
    "  img = plt.imread(m)\n",
    "  ax.imshow(img)\n",
    "  ax.xaxis.set_major_locator(ticker.NullLocator())\n",
    "  ax.yaxis.set_major_locator(ticker.NullLocator())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROBTBM-0ae1W"
   },
   "source": [
    "# Realizar inferência de métricas no conjunto de validação (val/valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SW0POpwYodO",
    "outputId": "8ff522f1-7179-41e6-b4e3-90784ba37c90"
   },
   "outputs": [],
   "source": [
    "curr_weight = os.path.join(SAVE_PATH, \"train/weights/best.pt\")\n",
    "!yolo task=detect mode=val data=\"{BASE_PATH}/trafficsign/data.yaml\" batch={BATCH_SIZE} device=0 model=\"{curr_weight}\" project={SAVE_PATH} name=\"val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlqoOJKyggIm"
   },
   "source": [
    "# Visualização dos gráficos das métricas de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "61qauyC1f6M7",
    "outputId": "c80fd20b-9c73-4e49-f236-62e5ba4e0527"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "metrics_img = glob(os.path.join(SAVE_PATH, \"val/*.png\"))\n",
    "n_img = len(metrics_img)\n",
    "n_cols = 2\n",
    "n_rows = int(n_img / n_cols) + (1 if n_img % n_cols != 0 else 0)\n",
    "_, axs = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "for m, ax in zip(metrics_img, axs):\n",
    "  img = plt.imread(m)\n",
    "  ax.imshow(img)\n",
    "  ax.xaxis.set_major_locator(ticker.NullLocator())\n",
    "  ax.yaxis.set_major_locator(ticker.NullLocator())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyUKgAYQYAfX"
   },
   "source": [
    "# Visualizar detecções no conjunto de teste (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaOhZ8c8YF4S",
    "outputId": "be0778fb-b38d-42b2-d027-a6ccb588025c"
   },
   "outputs": [],
   "source": [
    "curr_weight = os.path.join(SAVE_PATH, \"train/weights/best.pt\")\n",
    "!yolo task=detect mode=predict model=\"{curr_weight}\" source=\"{BASE_PATH}/trafficsign/images/test\" project=\"{SAVE_PATH}\" name=\"detect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zdCa3Hltw7HZ",
    "outputId": "c554a03c-11df-49e9-9c62-c67a866ff7b0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import matplotlib.ticker as ticker\n",
    "import random\n",
    "\n",
    "num_samples = 4 # numero de imagens para visualizar.\n",
    "all_dets = glob(os.path.join(SAVE_PATH, \"detect/*.png\"))\n",
    "n_cols = 2\n",
    "n_rows = int(num_samples / n_cols) + (1 if num_samples % n_cols != 0 else 0)\n",
    "_, axs = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "for m, ax in zip(random.sample(all_dets, num_samples), axs):\n",
    "  img = plt.imread(m)\n",
    "  ax.imshow(img)\n",
    "  ax.xaxis.set_major_locator(ticker.NullLocator())\n",
    "  ax.yaxis.set_major_locator(ticker.NullLocator())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7Ww23uSDWlB"
   },
   "source": [
    "<img src=\"http://lapix.ufsc.br/wp-content/uploads/2022/10/rodape-lapix.png\">"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
