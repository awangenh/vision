{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07UCeAb5diRN"
   },
   "source": [
    "![imagem](http://lapix.ufsc.br/wp-content/uploads/2022/09/NB-banner-PT.jpg)\n",
    "# 15.2.1.Notebook para Segmentação por Instância - Detectron2 (MaskRCNN)\n",
    "#### Novembro de 2024\n",
    "\n",
    "### Autores:\n",
    "<b>Autores</b>:\n",
    "\n",
    "*   Aldo von Wangenheim (aldo.vw@ufsc.br) [Review, Maintainer]\n",
    "*   Rodrigo de Paula e Silva Ribeiro (ribeiro.rodrigo@posgrad.ufsc.br)  [Review, Code, Dataset, Maintainer]\n",
    "\n",
    "\n",
    "CERTIFIQUE-SE DE TER INCIADO O AMBIENTE EM MODO <b>GPU</b> ANTES DE REALIZAR OS PROCEDIMENTOS.<br>\n",
    "NA TROCA DO AMBIENTE ELE <b><u>PERDE</u></b> TODOS OS DADOS BAIXADOS.\n",
    "\n",
    "AO RE-EXECUTAR OS PROCEDIMENTOS (ex. diminuir o batch size), <br>REINICIE O AMBIENTE PARA LIBERAR O CACHE DO PYTORCH (reiniciar não perde os dados da sessão).<br>(alt+m ou pelo menu \"Ambiente de Execução\")\n",
    "\n",
    "EXECUTE UTILIZANDO RUN ALL ou CTRL+F9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github.com/awangenh/vision/blob/master/jupyter/15.2.1.Segmenta%C3%A7%C3%A3o%20por%20Inst%C3%A2ncia%20-%20Detectron%20V2.ipynb\"><img align=\"left\"  src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\" src=\"https://www.lapix.ufsc.br/wp-content/uploads/2019/04/License-CC-BY-ND-4.0-orange.png\" alt=\"Creative Commons 4.0 License\" title=\"Creative Commons 4.0 License\"></a>&nbsp; &nbsp; <a href=\"\"><img align=\"left\" src=\"https://www.lapix.ufsc.br/wp-content/uploads/2019/04/Jupyter-Notebook-v.1.0-blue.png\" alt=\"Jupyter Version\" title=\"Jupyter Version\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\" src=\"https://img.shields.io/badge/python-3.10-greeng\" alt=\"Python Version\" title=\"Python Version\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5g7hEfqfb50",
    "outputId": "e6726057-2890-46ff-bfc7-b77b2186b1d2"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "!nvidia-smi\n",
    "!nvcc --version\n",
    "\n",
    "# Test if your notebook is running on Google Colab\n",
    "# You'll use this when choosing between doing interaction via ipywidgets or not.\n",
    "try:\n",
    "    import google.colab\n",
    "    _ON_COLAB = True\n",
    "except:\n",
    "    _ON_COLAB = False\n",
    "\n",
    "print('Running on Google Colab = ', _ON_COLAB)\n",
    "import os\n",
    "# Definir o caminho base\n",
    "if _ON_COLAB:\n",
    "    BASE_PATH = \"/content\"\n",
    "else:\n",
    "    BASE_PATH = \"/lapix\" # trocar para o base path do seu computador se estiver rodando localmente, deixar /lapix se estiver rodando nos conteiners lapix\n",
    "\n",
    "os.chdir(BASE_PATH) # garantir que está executando no caminho base definido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suprimir Avisos Gerais na saida do notebook\n",
    "Suprimir apenas \"avisos\", erros irá mostrar a causar e efetuará a parada do notebook normalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iP1CD-VoWJsu"
   },
   "source": [
    "# Configurações dos Loggers Externos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akusqLtXDhtP"
   },
   "source": [
    "## Descrição dos Loggers e suas funções.\n",
    "Este notebook oferece logging de informações do treino para ambiente externo.\n",
    "Mais especificamente para: [WandB](https://wandb.ai/) e [Neptune](https://neptune.ai/).<br>\n",
    "WandB e Neptune são gerenciadores de projetos de machine learning que possibilitam a comparação analítica de maneira facilitada entre vários treinos de um mesmo modelo comparando diferentes parâmetros.<br>\n",
    "Há ainda opções avançadas para salvar modelos e datasets na nuvem (necessita assinatura paga) de forma a facilitar a portabilidade entre diferentes frameworks de ML.<br>\n",
    "Para utilizá-los, é necessário acessar o site (clikar nos links acima) e efetuar um cadastro gratuito para obter uma chave de api.<br>\n",
    "Após, alterar no bloco abaixo, os locais indicados com as chaves e mudar a variável de ativação para \"True\".<br>\n",
    "Caso não deseje utilizar loggers externos, manter as variáveis de ativação em \"False\".<br>\n",
    "O [Detectron2](https://github.com/facebookresearch/detectron2), por padrão, ao final do treino, irá gerar um arquivo 'metrics.json', onde é possível visualizar e analisar os dados de treino e eventualmente montar seu próprio comparador analítico entre treinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0Q7NL61TL_T"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# EXTERNAL LOGGERS\n",
    "\"\"\"\n",
    "WANDB_LOGGER = False # Ativa o log das métricas básicas no wandb.ai, requer mais configurações abaixo.\n",
    "NPT_LOGGER = False # Ativa o log das métricas básicas no nepture.ai, requer mais configurações abaixo.\n",
    "\n",
    "\"\"\"\n",
    "# WANDB CONFIG\n",
    "\"\"\"\n",
    "WANDB_API_KEY = \"***\" # wandb.ai api-key, trocar *** por sua api key\n",
    "WANDB_PROJECT_NAME = \"Cones-Teste\" # Nome do projeto onde será logado as métricas (pode ser projeto já existente), caso deixe vazio será gerado um nome aleatório no wandb.ai\n",
    "WANDB_ENTITY = \"wndb_username\" # A entidade que está enviando os dados.\n",
    "WANDB_RUN_ID = \"\" # Em caso de resumo é necessário passar o RUN-ID para continuar logando as métricas na mesma run.\n",
    "\n",
    "\"\"\"\n",
    "# NEPTUNE CONFIG\n",
    "\"\"\"\n",
    "NPT_PROJECT_NAME = \"---\" # O nome do projeto para o qual será enviado os dados (definido no neptune.ai).\n",
    "NPT_TOKEN = \"***\" # A api token do neptune.ai, trocar *** pela sua api key fornecida no neptune.ai\n",
    "NPT_RUN_ID = \"\" # Em caso de resumo é necessário passar o RUN-ID para continuar logando na mesma run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TU3aDGtyWaCT",
    "outputId": "64cabe1b-bc18-4a6e-9273-e8c5bb86d544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.9 MB 3.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 182 kB 24.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 168 kB 12.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 166 kB 10.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 166 kB 50.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 162 kB 14.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 162 kB 9.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 158 kB 6.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 157 kB 22.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 157 kB 22.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 157 kB 27.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 157 kB 22.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 157 kB 25.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 157 kB 24.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 157 kB 21.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 156 kB 24.6 MB/s \n",
      "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 433 kB 4.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 829 kB 63.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 132 kB 62.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 59.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 55 kB 4.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 49.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 79 kB 8.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 140 kB 69.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 130 kB 59.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 67 kB 7.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 127 kB 71.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 66 kB 5.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 51 kB 7.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 48.4 MB/s \n",
      "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "INSTALL_LIBS = False # Setar para True para instalar localmente também (Não é necessário se estiver rodando nos conteiners Lapix)\n",
    "\n",
    "if _ON_COLAB:\n",
    "    INSTALL_LIBS = True\n",
    "\n",
    "if INSTALL_LIBS:\n",
    "    !pip install wandb -q\n",
    "    !pip install neptune-client -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentação por Instância x Segmentação Semântica (diferenças)\n",
    "Ambas as segmentações classificam a imagem a nível de pixel.\n",
    "\n",
    "A principal diferença entre elas é no modo como a imagem e as máscaras detectadas são tratadas.\n",
    "\n",
    "Na segmentação semântica, cada pixel na tela terá uma classificação e as máscaras de objetos encontrados são unificadas (ex: 3 carros na imagem, porém uma única máscara para os 3 carros).\n",
    "\n",
    "![imagem](https://drive.google.com/thumbnail?id=1xTcpqOMJaXc3QGUj2y7U5t-abSYihF7Y&sz=w400)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na segmentação por instância, somente as máscaras de objetos reconhecidos serão classificadas e extraidas (qualquer objeto na tela que não esteja no conjunto de dados é automaticamente descartado), e cada objeto terá uma máscara individual, permitindo detectar várias instâncias de um mesmo objeto.\n",
    "\n",
    "![imagem](https://drive.google.com/thumbnail?id=1qrm8HqWJHl-cDj7Jhqk37Ekk7aG_lLuo&sz=w400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYmRjYFSdUO-"
   },
   "source": [
    "# Simple Street Instance Test Dataset\n",
    "Este dataset é derivado do conjunto aberto \"street\": https://universe.roboflow.com/hmc-nbo1u/street-has4r\n",
    "Foi realizada uma limpeza, adequação de classes, verificação e adição de novas anotações.\n",
    "\n",
    "Este dataset é para fins didáticos de funcionamento de segmentação por instância.\n",
    "\n",
    "Classes:\n",
    "* car\n",
    "* bus\n",
    "* truck\n",
    "* traffic light\n",
    "* motorcycle\n",
    "* person\n",
    "\n",
    "Amostra de anotações:<br>\n",
    "![](https://drive.google.com/thumbnail?id=1B1z6p6FmU7KODn8hThMsGR-UrgohvfpN&sz=w400)\n",
    "![](https://drive.google.com/thumbnail?id=1syPez_Dgg1SJkcU5yjoroUXNH6EfqAhN&sz=w400)\n",
    "![](https://drive.google.com/thumbnail?id=17WMc9xcLXwIWaTqiUfNeiZw3N7PlwiGs&sz=w400)\n",
    "![](https://drive.google.com/thumbnail?id=1YCtFawtuVDWMugm-UvVaKNV7g3TkMZb8&sz=w400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6pvEJIWCPyZ"
   },
   "source": [
    "# 0 Definição das variáveis de controle (treino, resumo, batchsize, epoch, lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8fkhvOSJa72"
   },
   "source": [
    "<center>Diferenças das políticas de decaimento da Learning Rate.</center><br>\n",
    "LR_METHODS.COSINE: Nesta política, após o aquecimento (subida) a Learning Rate irá decair suavemente com tendência a 0.<br>\n",
    "LR_METHODS.STEP: Nesta política, após o aquecimento (subida) a Learning Rate irá decair por valores fixos e nos passos fixados previamente, tende a um valor específico resultado do decaimento do último passo.\n",
    "<br><br>\n",
    "<center>Exemplos de curvas das políticas de decaimento da Learning Rate.\n",
    "<br>(laranja escuro= curva suavizada, laranja claro= curva natural)</center><br>\n",
    "\n",
    "LR_METHODS.COSINE:<br>\n",
    "![](https://drive.google.com/thumbnail?id=1ih5TR3qpT17WZtMl-RjIH7HK39eJ_0hb&sz=w800)\n",
    "\n",
    "LR_METHODS.STEP:<br>\n",
    "![](https://drive.google.com/thumbnail?id=1p87kdvgwqcmpym9lDy_LKhsj_04ydkDM&sz=w800)\n",
    "\n",
    "## OneCycle\n",
    "É um método de convergência acelerada proposto por Leslie N. Smith em 2017.\n",
    "O método varia a taxa de aprendizado e momentum da rede de forma que a taxa de aprendizado sobe até um pico e depois decresce gradualmente, por outro lado,  o momentum da rede obedece uma curvatura inversa da taxa de aprendizagem como ilustrado abaixo.<br>\n",
    "![imagem](https://miro.medium.com/max/720/1*38YBWIKFwXN0YlNOVo_LOA.jpeg)\n",
    "\n",
    "O framework fast.ai implementa uma variação deste método e é um dos métodos mais utilizado no fast.ai. Também está disponível no framework pytorch (implementação original e do fast.ai). Este notebook utiliza-se da implementação do pytorch, deixando ao usuário a liberdade de escolha entre a variação do fast.ai ou o modo original.<br>Mais detalhes podem ser encontrados nos materiais a seguir:\n",
    "* https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html\n",
    "* A disciplined approach to neural network hyper-parameters: Part 1 — learning rate, batch size, momentum, and weight decay — https://arxiv.org/abs/1803.09820\n",
    "* Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates — https://arxiv.org/abs/1708.07120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tHFD4n3T_TyP",
    "outputId": "df546c98-2eb0-4653-dec3-43b79d9b1449"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "const senderChannel = new BroadcastChannel('logger'); senderChannel.postMessage('Bloco de Configuração: OK (Iniciando em modo Treino)');",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "#-- membros estáticos\n",
    "LR_METHODS = Enum(\"LR_METHODS\", \"COSINE FIXED STEP ONECYCLE\")\n",
    "#--\n",
    "\n",
    "\"\"\"\n",
    "# CONFIGS GENERICAS\n",
    "\"\"\"\n",
    "NUM_EPOCH = 35 # Define o número de épocas para rodar ex: 100\n",
    "SAVE_EPOCH = 5 # Define o intervalo de épocas para salvar, ex: de 1 em 1\n",
    "BSIZE = 12 # Define o batch_size, ex: 12\n",
    "LEARNING_RATE = 0.002 # Define a learnig rate base, ex: 0.01\n",
    "WARMUP_ITERS = 50 # Número de iterações iniciais para aquecimento da LR. Padrão: 1000\n",
    "\n",
    "# Define o método para learning rate adaptativa.\n",
    "# Atualmente disponíveis: LR_METHODS.COSINE, LR_METHODS.FIXED, LR_METHODS.STEP e LR_METHODS.ONECYCLE (ver gráficos/info no bloco acima)\n",
    "# LR_METHODS.FIXED >> mantém a learning rate fixa o tempo todo sem decaimento.\n",
    "LR_METHOD = LR_METHODS.ONECYCLE\n",
    "\n",
    "\"\"\"\n",
    "# COSINE CONFIGS (LR_METHODS.COSINE)\n",
    "\"\"\"\n",
    "# Define o momentum base para a LR no método Cosine.\n",
    "LR_MOMENTUM = 0.9\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# STEP CONFIGS (LR_METHODS.STEP)\n",
    "\"\"\"\n",
    "# Array das n% de decay em 0-1, ex: 60%, 80%, 90% = [0.6, 0.8, 0.9], primeiro decay aos 60% do conjunto treinado, segundo aos 80% e terceiro/último aos 90%.\n",
    "LR_STEPS_DECAY = [0.6, 0.8]\n",
    "# Define o quanto vai decair a Learning Rate atual em cada passo: LR_BASE = 0.1, decay1 = LR_BASE * STEP_RATE = 0.01, decay2 = NOVA_LR(0.01) * STEP_RATE = 0.001, etc..\n",
    "LR_STEP_RATE = 0.1\n",
    "\n",
    "\"\"\"\n",
    "# ONECYCLE CONFIGS (LR_METHODS.ONECYCLE)\n",
    "\"\"\"\n",
    "OC_LIMIT = 0.01 # limite maximo de crescimento da learning rate\n",
    "OC_MIN_MOMENTUM = 0.85 # momentum minimo\n",
    "OC_MAX_MOMENTUM = 0.95 # momentum maximo\n",
    "OC_THREE_PHASE = False # True para usar a versao original do Artigo. False para usar a modificação do pytorch/fast.ai (não publicado mas teoricamente melhor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# CONFIGS PARA RESUMO DE TREINO\n",
    "\"\"\"\n",
    "RESUMIR = False # False = novo treino, ao RESUMIR AS CONFIG ACIMA SAO IGNORADAS E CARREGADAS DO ARQUIVO DO MODELO (para evitar erros por diferença)\n",
    "PASTA_RESUMO = \"27-8-2022_12_32_40\" # pasta onde foi salvo o treino a ser resumido\n",
    "\n",
    "\"\"\"\n",
    "# CONFIGS DE PASTA PARA SALVAMENTO \n",
    "\"\"\"\n",
    "PROJECT_NAME = \"Detectron2_Instance\"\n",
    "GDRIVE_SAVE = False # Setar True e montar o drive na proxima célula para salvar as runs no drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kttr_buA2Vgz"
   },
   "source": [
    "# 1 Montar o google drive\n",
    "Apenas para usuarios do colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "g-O6aaWTSPig",
    "outputId": "69fa1a60-873c-49ae-bf3d-fcec4f41776c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    },
    {
     "data": {
      "application/javascript": "const senderChannel = new BroadcastChannel('logger'); senderChannel.postMessage('Montagem do Drive: OK');",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Caso queira salvar treinamento no google drive, rodar estar célular.\n",
    "if GDRIVE_SAVE:\n",
    "    from google.colab import drive\n",
    "    DRIVE_PATH = os.path.join(BASE_PATH, \"gdrive\")\n",
    "    drive.mount(DRIVE_PATH, force_remount=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aggX8JZm2pSn"
   },
   "source": [
    "# 2 Realizar o download dos arquivos necessários.\n",
    "Download e extração do dataset e demais arquivos necessários.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "UdAcG4mUSvCO",
    "outputId": "9ca4ba31-915d-46e7-cda4-e9032f82e709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1TxbWIbi6PEaMJnEVZZ-R4TNbwSWxNLCQ\n",
      "To: /content/cone_dataset.zip\n",
      "100% 111M/111M [00:00<00:00, 201MB/s] \n"
     ]
    },
    {
     "data": {
      "application/javascript": "const senderChannel = new BroadcastChannel('logger'); senderChannel.postMessage('Download e extração do dataset: OK');",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "# definir onde irá salvar\n",
    "if GDRIVE_SAVE:\n",
    "  RUNS_PATH = os.path.join(DRIVE_PATH,PROJECT_NAME)\n",
    "else:\n",
    "  RUNS_PATH = os.path.join(BASE_PATH,PROJECT_NAME)\n",
    "os.makedirs(RUNS_PATH, exist_ok=True)\n",
    "\n",
    "os.chdir(BASE_PATH)\n",
    "# download cones dataset\n",
    "!gdown 1wBtdJjlBqOD5Oqo-QUXP-Z4vn32LnuVH\n",
    "os.makedirs(os.path.join(BASE_PATH, \"dataset\"), exist_ok=True)\n",
    "!mv simple_street_segmentation.zip {BASE_PATH}/dataset/\n",
    "os.chdir(os.path.join(BASE_PATH, \"dataset\"))\n",
    "!unzip -qq -u simple_street_segmentation.zip\n",
    "!rm -rf simple_street_segmentation.zip\n",
    "os.chdir(BASE_PATH)\n",
    "print(\"Download e Extração do dataset FINALIZADA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZu_5x9D2sW9"
   },
   "source": [
    "# 3 Conversão de dados para o formato COCO.\n",
    "Realiza a conversão do formato labelme para [coco](https://cocodataset.org/#home) json. Caso não precise conversão (como é o caso do cones dataset, pule esta etapa), caso precise de outra conversão, realizar neste bloco.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "pR6cIO64Vv_b",
    "outputId": "fc44fe2c-1d0a-43be-fb38-2031a693ce0b"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "const senderChannel = new BroadcastChannel('logger'); senderChannel.postMessage('Conversão do dataset para formato COCO: OK');",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "if RESUMIR:\n",
    "  print(\"Conversão do dataset para formato COCO: Pulando etapa... (modo de resumo já possui essa conversão).\")\n",
    "else:\n",
    "  #!python label2coco.py \"{BASE_PATH}/dataset/\" --output \"coco_format.json\" # este dataset já está vindo no formato COCO, linha mantida apenas para referência\n",
    "  print(\"Dataset já está no formato coco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIHvgtnX3Ge0"
   },
   "source": [
    "# 4 Divisão do dataset em train, val e test.\n",
    "É usual em tarefas de Machine Learning e Deep Learning, utilizar-se de 2 a 3 subconjuntos extraidos do dataset principal.<br>\n",
    "Normalmente são nomeados como Train, Val e Test Split. Ou seja, divisão de treino, validação e teste.<br>\n",
    "A rede é treinada com o a divisão \"train\", de forma que as divisões val e test são desconhecidas para a rede. Desta forma é possível verificar situações como \"Overfitting\", caso que ocorre quando a rede vai bem no conjunto de treino e vai mal nos conjuntos de val e test (decora os dados mas não aprende de fato).\n",
    "<br>A proporção mais utilizada é a de: 70%, 15%, 15% no caso de train/val/test ou 70%/30% (train/val).\n",
    "Este notebook utiliza-se de 3 conjuntos na proporção 70/15/15.\n",
    "Ao final do treino é realizada uma inferência no conjunto 'val' automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "nzmRwbA7YJLX",
    "outputId": "e1b22927-03e1-4c31-df17-42a50169cc7d"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "const senderChannel = new BroadcastChannel('logger'); senderChannel.postMessage('Divisão train/val/test do dataset: OK');",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "def save_coco(file, images, annotations, categories):\n",
    "    with open(file, 'w') as coco:\n",
    "        json.dump({ 'images': images, 'annotations': annotations, 'categories': categories}, coco, indent=2, sort_keys=True)\n",
    "\n",
    "def filter_annotations(annotations, images):\n",
    "    image_ids = map(lambda i: int(i['id']), images)\n",
    "    image_ids = list(image_ids)\n",
    "    filtered = filter(lambda a: int(a['image_id']) in image_ids, annotations)\n",
    "    return list(filtered)\n",
    "\n",
    "if RESUMIR:\n",
    "  print(\"Divisão train/val/test do dataset: Pulando etapa... (modo de resumo já possui estas definições)\")\n",
    "else:\n",
    "  print(\"Dataset já possui divisão train/val/test\") # o dataset já está dividido em train,val e test, código mantido para referência.\n",
    "  \"\"\"\n",
    "  _train = 0.7\n",
    "  _val = 0.15\n",
    "  _test = 0.15\n",
    "\n",
    "  with open('/content/dataset/coco_format.json', 'r') as infile:\n",
    "    coco = json.load(infile)\n",
    "    images = coco['images']\n",
    "    annotations = coco['annotations']\n",
    "    categories = coco['categories']\n",
    "    train_set, y = train_test_split(images, train_size=_train)\n",
    "    val_set, test_set = train_test_split(y, train_size= (_val/(_val + _test)))\n",
    "    os.chdir(\"/content/\")\n",
    "    save_coco('train.json', train_set, filter_annotations(annotations, train_set), categories)\n",
    "    save_coco('val.json', val_set, filter_annotations(annotations, val_set), categories)\n",
    "    save_coco('test.json', test_set, filter_annotations(annotations, test_set), categories)\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Rvz7TD3qQk"
   },
   "source": [
    "# 5 Instalação do [Detectron2](https://github.com/facebookresearch/detectron2) direto do git oficial (última versão disponível).\n",
    "O detectron2 é um framework construído sobre o [PyTorch](https://pytorch.org/) pelo FAIR (Facebook Artificial Inteligence Research) que possibilita um alto nível de customização e uma grande variedade de modelos prontos para uso.<br>\n",
    "Para uma versão específica é necessário alterar o git alvo no código abaixo para a versão pretendida.<br>\n",
    "Para mais informações sobre o [Detectron2](https://github.com/facebookresearch/detectron2), verifique sua documentação [neste link](https://detectron2.readthedocs.io/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IywpOM5_w81c",
    "outputId": "d6fa4483-8213-485d-a3aa-0b1cd9480bc9"
   },
   "outputs": [],
   "source": [
    "if _ON_COLAB:\n",
    "    !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "else:\n",
    "    pass # Detectron2 já está instalado nos conteineres 'lapix'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIcIXGmr3ww4"
   },
   "source": [
    "# 6 Verificação da instalação e versão do Detectron2 e do PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2G2lz1eg4a_J",
    "outputId": "510e4241-13f5-4ce8-ec55-1e885a502817"
   },
   "outputs": [],
   "source": [
    "# verificar info da maquina\n",
    "import torch, detectron2\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySVWSMpP32Bk"
   },
   "source": [
    "# 7 Treinar a rede.\n",
    "Ao final do treino é realizado inferência no conjunto 'val'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poAAmdcMOWdd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.utils.events import get_event_storage\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.engine import HookBase\n",
    "from detectron2.solver.build import build_lr_scheduler, build_optimizer, get_default_optimizer_params\n",
    "from detectron2.solver.lr_scheduler import WarmupCosineLR, WarmupMultiStepLR, LRMultiplier, WarmupParamScheduler\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "from fvcore.common.param_scheduler import CosineParamScheduler, MultiStepParamScheduler, StepWithFixedGammaParamScheduler\n",
    "from collections import defaultdict\n",
    "import neptune.new as neptune\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "class ExternalLogger(HookBase):\n",
    "    \"\"\"\n",
    "    Hook para enviar os dados de treino para o WandB.ai e/ou Neptune.ai\n",
    "    \"\"\"\n",
    "    def __init__(self, period=20, npt=False, wndb=False, resume=False, maxiter = 0):\n",
    "        super().__init__()\n",
    "        self._period = period\n",
    "        self._npt = npt\n",
    "        self._wndb = wndb\n",
    "        self._resume = resume\n",
    "        self._last = -1\n",
    "        self._params = {\"batch_size\": BSIZE, \"epochs\": NUM_EPOCH, \"learning_rate\": LEARNING_RATE, \"scheduler\": LR_METHOD.name, \"iterations\": maxiter}\n",
    "        if self._npt:\n",
    "            if self._resume:\n",
    "                self._npt_run = neptune.init_run(project=NPT_PROJECT_NAME, api_token=NPT_TOKEN, with_id=NPT_RUN_ID)\n",
    "            else:\n",
    "                self._npt_run = neptune.init_run(project=NPT_PROJECT_NAME, api_token=NPT_TOKEN)\n",
    "        if self._wndb:\n",
    "            os.environ[\"WANDB_SILENT\"] = \"True\"\n",
    "            os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "            if self._resume:\n",
    "                self._wnd_run = wandb.init(project=WANDB_PROJECT_NAME, entity=WANDB_ENTITY, id=WANDB_RUN_ID, resume=\"must\")\n",
    "            else:\n",
    "                self._wnd_run = wandb.init(project=WANDB_PROJECT_NAME, entity=WANDB_ENTITY)\n",
    "        if not self._resume:\n",
    "            self._npt_run[\"parameters\"] = self._params\n",
    "            wandb.config.update(self._params)\n",
    "\n",
    "    def after_step(self):\n",
    "        if (self.trainer.iter + 1) % self._period == 0 or (self.trainer.iter == self.trainer.max_iter - 1):\n",
    "            storage = get_event_storage()\n",
    "            _iter = storage.iter\n",
    "            self._last = _iter\n",
    "            for k, (v, iter) in storage.latest_with_smoothing_hint(self._period).items():\n",
    "                if self._wndb:\n",
    "                    if self._resume:\n",
    "                        if wandb.run.step < _iter:\n",
    "                            wandb.log({f'{k.replace(\"/\", \"-\")}': v}, step=_iter)\n",
    "                    else:\n",
    "                        wandb.log({f'{k.replace(\"/\", \"-\")}': v}, step=_iter)\n",
    "                if self._npt:\n",
    "                    if self._resume:\n",
    "                        if self._npt_run[\"last_iter\"].fetch() < _iter:\n",
    "                            self._npt_run[k.replace(\"/\", \"-\")].log(v, step=_iter)\n",
    "                    else:\n",
    "                        self._npt_run[k.replace(\"/\", \"-\")].log(v, step=_iter)\n",
    "                        self._npt_run[\"last_iter\"] = _iter\n",
    "\n",
    "    def after_train(self):\n",
    "        storage = get_event_storage()\n",
    "        for k, (v, iter) in storage.latest_with_smoothing_hint(self._period).items():\n",
    "            if iter <= self._last:\n",
    "                continue\n",
    "            if self._wndb:\n",
    "                wandb.log({f'{k.replace(\"/\", \"-\")}': v}, step=iter)\n",
    "            if self._npt:\n",
    "                self._npt_run[k.replace(\"/\", \"-\")].log(v, step=iter)\n",
    "        if self._wndb:\n",
    "            self._wnd_run.finish()\n",
    "        if self._npt:\n",
    "            self._npt_run.stop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DeepUFSCTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"coco_val\")\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "        return COCOEvaluator(dataset_name=dataset_name, use_fast_impl=False, output_dir=output_folder)\n",
    "\n",
    "    @classmethod\n",
    "    def build_lr_scheduler(cls, cfg, optimizer):\n",
    "        name = cfg.SOLVER.LR_SCHEDULER_NAME\n",
    "        if name == \"WarmupMultiStepLR\":\n",
    "            steps = [x for x in cfg.SOLVER.STEPS if x <= cfg.SOLVER.MAX_ITER]\n",
    "            if len(steps) != len(cfg.SOLVER.STEPS):\n",
    "                logger = logging.getLogger(__name__)\n",
    "                logger.warning(\"SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\")\n",
    "            sched = MultiStepParamScheduler(\n",
    "              values=[cfg.SOLVER.GAMMA**k for k in range(len(steps) + 1)],\n",
    "              milestones=steps,\n",
    "              num_updates=cfg.SOLVER.MAX_ITER,\n",
    "            )\n",
    "        elif name == \"WarmupCosineLR\":\n",
    "            end_value = cfg.SOLVER.BASE_LR_END / cfg.SOLVER.BASE_LR\n",
    "            assert end_value >= 0.0 and end_value <= 1.0, end_value\n",
    "            sched = CosineParamScheduler(1, end_value)\n",
    "        elif name == \"WarmupStepWithFixedGammaLR\":\n",
    "            sched = StepWithFixedGammaParamScheduler(\n",
    "              base_value=1.0,\n",
    "              gamma=cfg.SOLVER.GAMMA,\n",
    "              num_decays=cfg.SOLVER.NUM_DECAYS,\n",
    "              num_updates=cfg.SOLVER.MAX_ITER,\n",
    "            )\n",
    "        elif name == \"OneCycleLR\":\n",
    "            return torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=cfg.ONECYCLE.LIMIT, base_momentum=cfg.ONECYCLE.MIN_MOMENTUM, max_momentum=cfg.ONECYCLE.MAX_MOMENTUM, total_steps=cfg.SOLVER.MAX_ITER, three_phase=cfg.ONECYCLE.THREE_PHASE)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown LR scheduler: {}\".format(name))\n",
    "\n",
    "        sched = WarmupParamScheduler(\n",
    "          sched,\n",
    "          cfg.SOLVER.WARMUP_FACTOR,\n",
    "          min(cfg.SOLVER.WARMUP_ITERS / cfg.SOLVER.MAX_ITER, 1.0),\n",
    "          cfg.SOLVER.WARMUP_METHOD,\n",
    "          cfg.SOLVER.RESCALE_INTERVAL,\n",
    "        )\n",
    "        return LRMultiplier(optimizer, multiplier=sched, max_iter=cfg.SOLVER.MAX_ITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mais modelos consulte: <a href=https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md>Detectron2 Model Zoo</a>\n",
    "\n",
    "Caso deseje trocar o modelo em uso altere as seguintes linhas:<br>\n",
    "<code>cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))<br>\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")</code><br>\n",
    "\n",
    "Para rodar em um dataset customizado, é necessário alterar o número de classes da última camada, alterando a seguinte linha:<br>\n",
    "<code>cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6 # numero de classes do dataset</code><br>\n",
    "\n",
    "Para modelos utilizados puramente para segmentação semântica, adicionar a seguinte linha:<br>\n",
    "<code>cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 6 # numero de classes para segmentação semantica</code><br>\n",
    "\n",
    "<b>Para outros modelos consulte a documentação do Detectron2 para quais atributos adicionais são necessários.</b>\n",
    "\n",
    "O Detectron2 espera dataset no formato coco com um arquivo json para cada split (train, test, val), as imagens podem estar na mesma pasta.<br>\n",
    "Para adicionar um dataset customizado, procure e edite as seguintes linhas:<br>\n",
    "<code>\n",
    "register_coco_instances(\"instance_train\", {}, \"/content/dataset/simple_street_segmentation/train/train.json\", \"/content/dataset/simple_street_segmentation/train\")<br>\n",
    "register_coco_instances(\"instance_val\", {}, \"/content/dataset/simple_street_segmentation/valid/valid.json\", \"/content/dataset/simple_street_segmentation/valid\")<br>\n",
    "</code>\n",
    "\n",
    "O formato para registrar um dataset com a função register_coco_instances segue abaixo:<br>\n",
    "<code>register_coco_instances(\"nome_para_localizar\", {}, \"caminho para o arquivo json\", \"caminho para as imagens\")</code><br>\n",
    "\n",
    "Para adicioanr ao CFG, procure e altere as seguintes linhas:<br>\n",
    "<code>cfg.DATASETS.TRAIN = (\"instance_train\",)<br>\n",
    "cfg.DATASETS.TEST = (\"instance_val\",)</code><br>\n",
    "\n",
    "Altere para:<br>\n",
    "<code>cfg.DATASETS.TRAIN = (\"nome_registrado_para_spli_train\",)<br>\n",
    "cfg.DATASETS.TEST = (\"nome_registrado_para_spli_validation\",)</code><br>\n",
    "\n",
    "Outras opções estão comentadas no código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_DxNHSCdxSln",
    "outputId": "b9fe2d0b-55b0-4e82-a60e-32242871322a"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.config import CfgNode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import PeriodicWriter\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "if RESUMIR:\n",
    "  print(\"Modo de resumo selecionado: Pulando etapa de treinamento novo\")\n",
    "else:\n",
    "  time_now = datetime.datetime.now(pytz.timezone(\"America/Sao_Paulo\"))\n",
    "  _msg = \"Iniciando treino: OK (treino iniciado em {dia}/{mes}/{ano} as {hora}:{minuto}:{segundo})\".format(dia=time_now.day, mes=time_now.month, ano=time_now.year, hora=time_now.hour, minuto=time_now.minute, segundo=time_now.second)\n",
    "  print(_msg)\n",
    "\n",
    "  setup_logger()\n",
    "\n",
    "  cfg = get_cfg()\n",
    "  cfg.ONECYCLE = CfgNode({\"LIMIT\": 0.01, \"MAX_MOMENTUM\": 0.95, \"MIN_MOMENTUM\": 0.85, \"THREE_PHASE\": False})\n",
    "\n",
    "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"))\n",
    "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\")\n",
    "\n",
    "  ##-- Definir os caminhos dos datasets\n",
    "  DatasetCatalog.clear()\n",
    "  MetadataCatalog.clear()\n",
    "  register_coco_instances(\"instance_train\", {}, os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/train/train.json\"), os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/train\"))\n",
    "  register_coco_instances(\"instance_val\", {}, os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/valid/valid.json\"), os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/valid\"))\n",
    "  cfg.DATASETS.TRAIN = (\"instance_train\",)\n",
    "  cfg.DATASETS.TEST = (\"instance_val\",)\n",
    "  ##-- END definir caminhos datasets\n",
    "\n",
    "  ##---------CONFIGURACOES COMEÇAM DAQUI PARA BAIXO ------------------------##\n",
    "  cfg.DATALOADER.NUM_WORKERS = 1 # numero de subprocessos para usar no dataloader para pré-carregar as imagens (via cpu). Depende da quantidade de cores do cpu e da memoria disponível no sistema. [2-4]\n",
    "  cfg.SOLVER.BASE_LR = LEARNING_RATE\n",
    "  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 # qtos rois da RPN vão ser usados para verificar region/classification loss durante o treino, ideal multiplo de 2.\n",
    "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6 # numero de classes do nosso dataset\n",
    "  cfg.SOLVER.IMS_PER_BATCH = BSIZE # \n",
    "  cfg.MODEL.RPN.NMS_THRESH = 0.7\n",
    "  cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.7]\n",
    "\n",
    "  #Calculando iteracao em epoch\n",
    "  NR_IMG = len(DatasetCatalog.get('instance_train'))\n",
    "  EPOCH = NR_IMG / cfg.SOLVER.IMS_PER_BATCH\n",
    "  cfg.SOLVER.MAX_ITER = int(NUM_EPOCH * EPOCH) #\n",
    "  cfg.SOLVER.WARMUP_ITERS = WARMUP_ITERS\n",
    "  if LR_METHOD == LR_METHODS.COSINE:\n",
    "    cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "    cfg.SOLVER.MOMENTUM = LR_MOMENTUM\n",
    "  elif LR_METHOD == LR_METHODS.STEP:\n",
    "    cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupMultiStepLR\"\n",
    "    cfg.SOLVER.GAMMA = LR_STEP_RATE\n",
    "    cfg.SOLVER.STEPS = tuple( [int(cfg.SOLVER.MAX_ITER*LR_STEPS_DECAY[i]) for i in range(len(LR_STEPS_DECAY))])\n",
    "  elif LR_METHOD == LR_METHODS.FIXED:\n",
    "    cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupMultiStepLR\"\n",
    "    cfg.SOLVER.STEPS = []\n",
    "  elif LR_METHOD == LR_METHODS.ONECYCLE:\n",
    "    cfg.SOLVER.LR_SCHEDULER_NAME = \"OneCycleLR\"\n",
    "    cfg.ONECYCLE.LIMIT = OC_LIMIT\n",
    "    cfg.ONECYCLE.MIN_MOMENTUM = OC_MIN_MOMENTUM\n",
    "    cfg.ONECYCLE.MAX_MOMENTUM = OC_MAX_MOMENTUM\n",
    "    cfg.ONECYCLE.THREE_PHASE = OC_THREE_PHASE\n",
    "    cfg.SOLVER.WARMUP_ITERS = 0\n",
    "    cfg.SOLVER.STEPS = []\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "  EPOCH_RATIO = NUM_EPOCH / SAVE_EPOCH\n",
    "  # checkpoint period faz o dt salvar o modelo atual a cada x iterações definidas aqui\n",
    "  cfg.SOLVER.CHECKPOINT_PERIOD = int(cfg.SOLVER.MAX_ITER/EPOCH_RATIO) #\n",
    "\n",
    "  #cfg.TEST.EVAL_PERIOD = 1000 # nao necessario agora, periodo o qual durante o treino ele vai fazer um eval com o conjunto \"derma_val\" para acompanhamento apenas\n",
    "\n",
    "  ##-------------END CONFG -------###\n",
    "\n",
    "  #config de dir\n",
    "  current_run = datetime.datetime.now(pytz.timezone(\"America/Sao_Paulo\"))\n",
    "  dirname = \"{dia}-{mes}-{ano}_{hora}_{minuto}_{segundo}\".format(dia=current_run.day, mes=current_run.month, ano=current_run.year, hora=current_run.hour, minuto=current_run.minute, segundo=current_run.second)\n",
    "  OUTDIR = os.path.join(RUNS_PATH, dirname)\n",
    "  os.makedirs(OUTDIR, exist_ok=True)\n",
    "  cfg.OUTPUT_DIR = OUTDIR\n",
    "\n",
    "\n",
    "  with open(os.path.join(OUTDIR, 'mask_instance_R50.yml'),'w') as f:\n",
    "    f.write(cfg.dump())\n",
    "\n",
    "  trainer = DeepUFSCTrainer(cfg)\n",
    "\n",
    "  if WANDB_LOGGER or NPT_LOGGER:\n",
    "    exlogger_hook = ExternalLogger(npt=NPT_LOGGER, wndb=WANDB_LOGGER, resume=False, maxiter=cfg.SOLVER.MAX_ITER)\n",
    "    trainer.register_hooks([exlogger_hook])\n",
    "  \n",
    "  trainer.resume_or_load(resume=False)\n",
    "  trainer.train()\n",
    "\n",
    "  #--msg logger--#\n",
    "  time_now = datetime.datetime.now(pytz.timezone(\"America/Sao_Paulo\"))\n",
    "  _msg = \"Treino terminado em {dia}/{mes}/{ano} as {hora}:{minuto}:{segundo})\".format(dia=time_now.day, mes=time_now.month, ano=time_now.year, hora=time_now.hour, minuto=time_now.minute, segundo=time_now.second)\n",
    "  print(_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOTKbp-W4LvC"
   },
   "source": [
    "# 8 Realizar inferência com o conjunto test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TrCXxCsxUGs",
    "outputId": "f3a10d34-769d-4d7f-f0fe-db3a97a5868f"
   },
   "outputs": [],
   "source": [
    "from detectron2.config import CfgNode\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "import torch\n",
    "cfg_test = get_cfg()\n",
    "cfg_test.ONECYCLE = CfgNode({\"LIMIT\": 0.01, \"MAX_MOMENTUM\": 0.95, \"MIN_MOMENTUM\": 0.85, \"THREE_PHASE\": False})\n",
    "cfg_test.merge_from_file(os.path.join(OUTDIR, \"mask_instance_R50.yml\"))\n",
    "cfg_test.MODEL.WEIGHTS = os.path.join(OUTDIR, \"model_final.pth\")\n",
    "with torch.no_grad():\n",
    "  predictor = DefaultPredictor(cfg_test)\n",
    "  model = predictor.model\n",
    "  register_coco_instances(\"instance_test\", {}, os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/test/test.json\"), os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/test\"))\n",
    "  test_dir = os.path.join(BASE_PATH,\"instance_test\")\n",
    "  os.makedirs(test_dir, exist_ok=True)\n",
    "  evaluator = COCOEvaluator(\"instance_test\", output_dir=test_dir)\n",
    "  test_loader = build_detection_test_loader(cfg_test, \"instance_test\")\n",
    "  print(inference_on_dataset(model, test_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQddVzjonSG4"
   },
   "source": [
    "# 9 Visualização das Detecções no conjunto test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, cv2, random, math\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import matplotlib.pyplot as plt\n",
    "cfg_test = get_cfg()\n",
    "cfg_test.ONECYCLE = CfgNode({\"LIMIT\": 0.01, \"MAX_MOMENTUM\": 0.95, \"MIN_MOMENTUM\": 0.85, \"THREE_PHASE\": False})\n",
    "cfg_test.merge_from_file(os.path.join(OUTDIR, \"mask_instance_R50.yml\"))\n",
    "cfg_test.MODEL.WEIGHTS = os.path.join(OUTDIR, \"model_final.pth\")\n",
    "dataset_dicts = DatasetCatalog.get('instance_test')\n",
    "num_samples = 6 # número de amostra para visualizar\n",
    "figure, ax = plt.subplots(nrows=math.ceil(num_samples/2), ncols=2, figsize=(12,18), constrained_layout=True)\n",
    "start_row = 0\n",
    "start_col = 0\n",
    "with torch.no_grad():\n",
    "  predictor = DefaultPredictor(cfg_test)\n",
    "  model = predictor.model\n",
    "  for det in random.sample(dataset_dicts, num_samples):\n",
    "    img = cv2.imread(det[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get('instance_test'), scale=1.75)\n",
    "    out = v.draw_instance_predictions(outputs['instances'][outputs['instances'].scores > 0.75].to(\"cpu\"))\n",
    "    #cv2_imshow(out.get_image()[:, :, ::-1])\n",
    "    ax[start_row, start_col].imshow(out.get_image())\n",
    "    ax[start_row, start_col].set_axis_off()\n",
    "    ax[start_row, start_col].set_xticklabels([])\n",
    "    ax[start_row, start_col].set_yticklabels([])\n",
    "    start_col = start_col + 1\n",
    "    if start_col == 2:\n",
    "      start_row = start_row + 1\n",
    "      start_col = 0\n",
    "figure.subplots_adjust(wspace=0, hspace=0)\n",
    "#figure.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYRR5IYf4i9K"
   },
   "source": [
    "# 10 Visualização dos dados de treino(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P59Y34WeOoHB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "metric_file = os.path.join(OUTDIR, \"metrics.json\")\n",
    "metrics = []\n",
    "with open(metric_file, 'r') as infile:\n",
    "  for line in infile.readlines():\n",
    "    metrics.append(json.loads(line))\n",
    "\n",
    "APmetrics = metrics[-1] if \"bbox/AP\" in metrics[-1].keys() else None\n",
    "if APmetrics is not None:\n",
    "  metrics.pop(-1)\n",
    "  APmetrics.pop('iteration', None) # não precisamos de iteration nos AP finais\n",
    "\n",
    "mt = dict()\n",
    "for k in metrics[0].keys():\n",
    "  _temp = [metrics[i][k] for i in range(len(metrics))]\n",
    "  mt.update({k: _temp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLoW8Q8ZBAPR",
    "outputId": "45b3761a-b823-4f04-8b3a-ada04c89b164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys válidas: dict_keys(['data_time', 'eta_seconds', 'fast_rcnn/cls_accuracy', 'fast_rcnn/false_negative', 'fast_rcnn/fg_cls_accuracy', 'iteration', 'loss_box_reg', 'loss_cls', 'loss_rpn_cls', 'loss_rpn_loc', 'lr', 'roi_head/num_bg_samples', 'roi_head/num_fg_samples', 'rpn/num_neg_anchors', 'rpn/num_pos_anchors', 'time', 'total_loss', 'validation_loss_box_reg', 'validation_loss_cls', 'validation_loss_rpn_cls', 'validation_loss_rpn_loc', 'validation_total_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys válidas:\", mt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "2SL1IO9zPcKM",
    "outputId": "23b9fc68-ca0f-4646-fa73-919ac7aec042"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "keys = [\"total_loss\", \"lr\", \"mask_rcnn/accuracy\", \"loss_mask\"] # adicionar keys válidas para mais plots.\n",
    "\n",
    "fig = plt.figure(figsize=(15,6), dpi=300)\n",
    "fig.subplots_adjust(hspace=0.7, wspace=0.4)\n",
    "row_index = 2\n",
    "line_index = (len(keys)//row_index)+1 if len(keys)%row_index != 0 else len(keys)//row_index\n",
    "plotcount = 1\n",
    "for k in keys:\n",
    "  _ax = fig.add_subplot(line_index, row_index, plotcount)\n",
    "  _ax.set_yscale('linear')\n",
    "  _ax.plot(mt[\"iteration\"], mt[k], linewidth=2.0)\n",
    "  _ax.set_xlabel('Iterations', fontsize=10)\n",
    "  _ax.set_title(k, fontsize=10)\n",
    "  plt.grid()\n",
    "  plotcount +=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "mmXfjBZmP6e5",
    "outputId": "a1c0ff35-3e9a-4e38-e818-857d897d23f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ff9c19c1-e49d-4551-99c6-80f9015e1911\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bbox/AP</th>\n",
       "      <td>24.176695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/AP-Cones</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/AP-blue_cone</th>\n",
       "      <td>33.992951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/AP-large_orange_cone</th>\n",
       "      <td>27.784366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/AP-orange_cone</th>\n",
       "      <td>25.078032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/AP-unknown_cone</th>\n",
       "      <td>0.683135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/AP-yellow_cone</th>\n",
       "      <td>33.344991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/AP50</th>\n",
       "      <td>47.809784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/AP75</th>\n",
       "      <td>22.028456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/APl</th>\n",
       "      <td>77.623762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/APm</th>\n",
       "      <td>54.100722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox/APs</th>\n",
       "      <td>22.604230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff9c19c1-e49d-4551-99c6-80f9015e1911')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ff9c19c1-e49d-4551-99c6-80f9015e1911 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ff9c19c1-e49d-4551-99c6-80f9015e1911');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                   0\n",
       "bbox/AP                    24.176695\n",
       "bbox/AP-Cones                    NaN\n",
       "bbox/AP-blue_cone          33.992951\n",
       "bbox/AP-large_orange_cone  27.784366\n",
       "bbox/AP-orange_cone        25.078032\n",
       "bbox/AP-unknown_cone        0.683135\n",
       "bbox/AP-yellow_cone        33.344991\n",
       "bbox/AP50                  47.809784\n",
       "bbox/AP75                  22.028456\n",
       "bbox/APl                   77.623762\n",
       "bbox/APm                   54.100722\n",
       "bbox/APs                   22.604230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-- Visualizar inferência AP como tabela --\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "if APmetrics is not None:\n",
    "  df = pd.DataFrame.from_dict(APmetrics, orient='index') # key como linhas\n",
    "  #df = pd.DataFrame(APmetrics, index=[0,]) # key como colunas\n",
    "  display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvTSRn9UDLs5"
   },
   "source": [
    "# 11 Bloco para resumir um treino parado anteriormente [RESUMIR = True]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJ1W7zeEDgxC"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "if RESUMIR:\n",
    "  pasta_para_resumir = PASTA_RESUMO\n",
    "  if pasta_para_resumir == \"\":\n",
    "    all_runs = glob(os.path.join(RUNS_PATH,\"*/\"))\n",
    "    lrt = len(RUNS_PATH)\n",
    "    last_date = None\n",
    "    last_run = None\n",
    "    last_time = None\n",
    "    for _run in all_runs:\n",
    "      _date, _time = _run[lrt:-1].split('2022')\n",
    "      run_date = time.strptime(_date + '2022', \"%d-%m-%Y\")\n",
    "      run_hour, run_min, run_sec = _time.strip('_').split('_')\n",
    "      run_time = run_hour*60 + run_min*60 + run_sec\n",
    "      if last_date is None:\n",
    "        last_date = run_date\n",
    "        last_run = _run\n",
    "        last_time = run_time\n",
    "      elif run_date > last_date:\n",
    "        lastaadptação_date = run_date\n",
    "        last_run = _run\n",
    "        last_time = run_time\n",
    "      elif run_date == last_date:\n",
    "        if run_time > last_time:\n",
    "          last_date = run_date\n",
    "          last_run = _run\n",
    "          last_time = run_time\n",
    "      else:\n",
    "        pass\n",
    "    pasta_para_resumir = last_run\n",
    "  else:\n",
    "    pasta_para_resumir = os.path.join(RUNS_PATH, PASTA_RESUMO)\n",
    "\n",
    "  print(\"Resumindo do diretorio:\", pasta_para_resumir)\n",
    "  models = glob(os.path.join(pasta_para_resumir, \"*.pth\"))\n",
    "  selected_model = None\n",
    "  aux = 0\n",
    "  for m in models:\n",
    "    numbers = ''.join([x for x in m if x.isdigit()])\n",
    "    if int(numbers) > aux:\n",
    "      selected_model = m\n",
    "      aux = int(numbers)\n",
    "  print(\"Resumindo do modelo:\", selected_model)\n",
    "  time_now = datetime.datetime.now(pytz.timezone(\"America/Sao_Paulo\"))\n",
    "  \n",
    "  _msg = \"Iniciando configurações de resumo: OK\"\n",
    "  print(_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoxV1la6DK6f"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "if RESUMIR:\n",
    "  time_now = datetime.datetime.now(pytz.timezone(\"America/Sao_Paulo\"))\n",
    "  _msg = \"Iniciando resumo de treino: OK (resumo iniciado em {dia}/{mes}/{ano} as {hora}:{minuto}:{segundo})\".format(dia=time_now.day, mes=time_now.month, ano=time_now.year, hora=time_now.hour, minuto=time_now.minute, segundo=time_now.second)\n",
    "  print(_msg)\n",
    "\n",
    "  setup_logger()\n",
    "\n",
    "  RUNS_PATH = pasta_para_resumir # definindo run path de resumo\n",
    "  cfg = get_cfg()\n",
    "  cfg.ONECYCLE = CfgNode({\"LIMIT\": 0.01, \"MAX_MOMENTUM\": 0.95, \"MIN_MOMENTUM\": 0.85, \"THREE_PHASE\": False})\n",
    "  cfg.merge_from_file(os.path.join(RUNS_PATH,\"mask_instance_R50.yml\"))\n",
    "  cfg.MODEL.WEIGHTS = selected_model\n",
    "  DatasetCatalog.clear()\n",
    "  MetadataCatalog.clear()\n",
    "  register_coco_instances(\"instance_train\", {}, os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/train/train.json\"), os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/train\"))\n",
    "  register_coco_instances(\"instance_val\", {}, os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/valid/valid.json\"), os.path.join(BASE_PATH, \"dataset/simple_street_segmentation/valid\"))\n",
    "  print(\"Executando: \" + str(cfg.SOLVER.MAX_ITER) + \" iterations.\")\n",
    "  trainer = DeepUFSCTrainer(cfg)\n",
    "\n",
    "  if WANDB_LOGGER or NPT_LOGGER:\n",
    "    exlogger_hook = ExternalLogger(npt=NPT_LOGGER, wndb=WANDB_LOGGER, resume=True)\n",
    "    trainer.register_hooks([exlogger_hook])\n",
    "  trainer.resume_or_load(resume=True) # True para resumir do checkpoint encontrado ou do melhor peso encontrado.\n",
    "  trainer.train()\n",
    "  time_now = datetime.datetime.now(pytz.timezone(\"America/Sao_Paulo\"))\n",
    "\n",
    "  \n",
    "  _msg = \"Resumo de treino finalizado em {dia}/{mes}/{ano} as {hora}:{minuto}:{segundo})\".format(dia=time_now.day, mes=time_now.month, ano=time_now.year, hora=time_now.hour, minuto=time_now.minute, segundo=time_now.second)\n",
    "  print(_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_v5z2G5w0Lu"
   },
   "source": [
    "<img src=\"http://lapix.ufsc.br/wp-content/uploads/2022/10/rodape-lapix.png\">\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "VnVY1FTo36KP",
    "_tB-8ebt4q_2"
   ],
   "gpuClass": "premium",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
