{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner cnns ppgcc ufsc](../banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.00-IPython-Beyond-Normal-Python.ipynb\"><img align=\"left\"  src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/License-CC-BY-ND-4.0-orange.png\" alt=\"Creative Commons 4.0 License\" title=\"Creative Commons 4.0 License\"></a>&nbsp; &nbsp; <a href=\"\"><img align=\"left\" src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Jupyter-Notebook-v.1.0-blue.png\" alt=\"Jupyter Version\" title=\"Jupyter Version\"></a>&nbsp; &nbsp;<a href=\"\"><img align=\"left\"  src=\"http://www.lapix.ufsc.br/wp-content/uploads/2019/04/Python-v.3.7-green.png\" alt=\"Python Version\" title=\"Python Version\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06.2.Segmentação por Crescimento de Regiões - Algoritmos Avançados\n",
    "\n",
    "A busca pelo sonho de consumo do algoritmo genérico para dividir uma imagem nos objetos ali representados levou ao desenvolvimento de algoritmos de segmentação bastante elaborados, que tentavam unir várias técnicas diferentes e várias representações diferentes do conteúdo de uma imagem: grafos dos objetos na imagem, representação de longos gradientes suaves por grandes regiões da imagem representando o mesmo objeto que variava de luminosidade, similaridade de pixel baseada em características específicas de imagens de satélite ou outras e por aí vai. Alguns players de peso como a NASA tentaram a sua sorte neste tipo de algoritmo.\n",
    "\n",
    "A maioria desses algoritmos foram implementados em linguagens de programação compiladas e existiram apenas na forma de executáveis que podiam ser baixados ou de código fonte em linguagem C ou C++. Como a pesquisa nesses algoritmos é anterior ao grande sucesso da linguagem Python, que estamos vendo agora, e as pesquisas agora estão voltadas para o desenvolvimento de algoritmos baseados em aprendizado profundo, muito poucos dos algoritmos que discutimos na nossa aula de segmentação avançada acabaram recebendo uma implementação em Python. O algoritmo de segmentação baseado em gráficos de Felzenszwalb & Huttenlocher, que possui um nome tão prosaico que ele só é citado pelas suas iniciais FH, é um dos poucos exemplos que nós podemos executar em Python. Abaixo vão alguns exemplos de sua execução.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph-Based Methods: the Felzenszwalb & Huttenlocher Algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKit F&H with Grayscale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b72c5ea818e43a28954eddc02ec7152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='scale', max=300, min=-100), FloatSlider(value=0.5, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "from skimage.data import astronaut\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "image = cv2.imread(\"../data/ct-02.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "#image = img_as_float(img[::2, ::2])\n",
    "\n",
    "\n",
    "def my_fh(scale=100, sigma=0.5, min_size=50, colormap='magma'):\n",
    "    global image\n",
    "    colormap = eval('plt.cm.' + colormap)\n",
    "    segments_fh = felzenszwalb(image, scale=scale, sigma=sigma, min_size=min_size)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15, 7), sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].imshow(mark_boundaries(image, segments_fh))\n",
    "    ax[0].set_title('Original with Boundaries: F&H')\n",
    "\n",
    "    ax[1].imshow(segments_fh, cmap=colormap, interpolation='nearest')\n",
    "    ax[1].set_title('Segments: Felzenszwalb & Huttenlocher')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interactive(my_fh, scale=100, sigma=0.5, min_size=50, colormap = ['nipy_spectral', 'hot', 'magma', 'seismic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKit F&H with Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c229b6ea85499680e4e2c41648b614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='scale', max=300, min=-100), FloatSlider(value=0.5, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "from skimage.data import astronaut\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "img = cv2.imread(\"../data/car-01.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image = img_as_float(img[::2, ::2])\n",
    "\n",
    "\n",
    "def my_fh(scale=100, sigma=0.5, min_size=50):\n",
    "    global image\n",
    "    segments_fh = felzenszwalb(image, scale=scale, sigma=sigma, min_size=min_size)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(19, 7), sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].imshow(mark_boundaries(image, segments_fh))\n",
    "    ax[0].set_title('Original with Boundaries: F&H')\n",
    "\n",
    "    ax[1].imshow(segments_fh, cmap=plt.cm.nipy_spectral, interpolation='nearest')\n",
    "    ax[1].set_title('Segments: Felzenszwalb & Huttenlocher')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interactive(my_fh, scale=100, sigma=0.5, min_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEGBIS F&H Implementation\n",
    "\n",
    "Here we will use the **PEGBIS** *(Python Efficient Graph-Based Image Segmentation)*, a Python implementation by Ghassem Alaee of the \"Efficient Graph-Based Image Segmentation\" paper written by P. Felzenszwalb, D. Huttenlocher. The paper is available: http://cs.brown.edu/~pff/papers/seg-ijcv.pdf. The C++ implementation is written by the author and is available on: http://cs.brown.edu/~pff/segment/.  You'll find the original author's implementation in https://github.com/salaee/pegbis. The version we are using here had a few adaptations and Python-updates by me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this once (or each time you restart the kernel if you're using Colab)\n",
    "# Code below downloads the version stored in my mirror\n",
    "# wget parameters: \n",
    "# --backups=1 : renames original file with .1 suffix and writes new file to the intended filename\n",
    "# -q : run quiet unless there's an error\n",
    "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/segment_graph.py\n",
    "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/filter.py\n",
    "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/fh_segment.py\n",
    "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/disjoint_set.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f5d5121cc24cb6b13752ce739b46c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='scale', max=1000, min=1), FloatSlider(value=0.5, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.my_pegbis(scale=100, sigma=0.5, min_size=50)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Segment an image:\n",
    "# Returns a color image representing the segmentation.\n",
    "#\n",
    "# Inputs:\n",
    "#           in_image: image to segment.\n",
    "#           sigma: to smooth the image.\n",
    "#           k: constant for threshold function.\n",
    "#           min_size: minimum component size (enforced by post-processing stage).\n",
    "#\n",
    "# Returns:\n",
    "#           num_ccs: number of connected components in the segmentation.\n",
    "# --------------------------------------------------------------------------------\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from filter import *\n",
    "from segment_graph import *\n",
    "from fh_segment import *\n",
    "import time\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "\n",
    "sigma = 0.5\n",
    "scale = 100\n",
    "min_size = 50\n",
    "input_path = \"../data/car-01.jpg\"\n",
    "\n",
    "# Loading the image\n",
    "#input_image = ndimage.imread(input_path, flatten=False, mode=None)\n",
    "input_image = plt.imread(input_path)\n",
    "\n",
    "def my_pegbis(scale=100, sigma=0.5, min_size=50):\n",
    "    global input_image\n",
    "\n",
    "    print(\"processing...\")\n",
    "    output_image, elapsed_time = fh_segment(input_image, sigma, scale, min_size)\n",
    "    print(\"Execution time: \" + str(int(elapsed_time / 60)) + \" minute(s) and \" + str(int(elapsed_time % 60)) + \" seconds\")\n",
    "    # displaying the result\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(14, 7), sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].imshow(input_image)\n",
    "    ax[0].set_title('Original')\n",
    "\n",
    "    ax[1].imshow(output_image)\n",
    "    ax[1].set_title('Segments: Felzenszwalb & Huttenlocher')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact_manual(my_pegbis, scale=(1, 1000), sigma=(0.1, 3.0), min_size=(10, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "* General tricks for displaying images were from here: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html\n",
    "* We also used a few general tips from: https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rodape lapix ufsc](../rodape-CC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "20",
    "lenVar": "60"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
